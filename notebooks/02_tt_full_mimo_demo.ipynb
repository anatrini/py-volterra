{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor-Train Volterra for Full MIMO Systems\n",
    "\n",
    "This notebook demonstrates **Tensor-Train (TT) decomposition** for full Multi-Input Multi-Output (MIMO) Volterra systems.\n",
    "\n",
    "## The Curse of Dimensionality in Volterra Models\n",
    "\n",
    "A full $N$-th order Volterra model for a MIMO system with $I$ inputs, $O$ outputs, and memory $M$ requires:\n",
    "$$\n",
    "\\text{Parameters} = O \\cdot I^N \\cdot M^N\n",
    "$$\n",
    "\n",
    "**Example:** For $I=3$ inputs, $O=2$ outputs, $N=3$ order, $M=10$ memory:\n",
    "- Full model: $2 \\times 3^3 \\times 10^3 = 54{,}000$ parameters\n",
    "- Storage explodes exponentially with $N$ and $M$!\n",
    "\n",
    "## Tensor-Train Decomposition\n",
    "\n",
    "TT decomposition factorizes the Volterra kernel tensor into a **product of low-rank cores**:\n",
    "$$\n",
    "\\mathcal{H}(m_1, \\ldots, m_N) = \\mathbf{G}_1[m_1] \\cdot \\mathbf{G}_2[m_2] \\cdots \\mathbf{G}_N[m_N]\n",
    "$$\n",
    "\n",
    "where each core $\\mathbf{G}_k[m_k]$ is a matrix of size $r_{k-1} \\times r_k$ (with $r_0 = r_N = 1$).\n",
    "\n",
    "**Benefits:**\n",
    "- **Parameters**: $O(N \\cdot M \\cdot I \\cdot r^2)$ instead of $O(I^N \\cdot M^N)$\n",
    "- **Example**: With $r=3$: $3 \\times 10 \\times 3 \\times 3^2 = 810$ parameters (67× reduction!)\n",
    "- **Scalable**: Works for high orders ($N > 5$) and long memory ($M > 20$)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "from volterra import TTVolterraMIMO\n",
    "\n",
    "np.random.seed(456)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Generate MIMO Nonlinear System Data\n",
    "\n",
    "We'll create a 2-input, 2-output (MIMO) system with:\n",
    "- **Linear crosstalk**: output 1 depends on both inputs\n",
    "- **Nonlinear interactions**: quadratic and cubic terms\n",
    "- **Memory effects**: IIR filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System configuration\n",
    "I, O = 2, 2  # 2 inputs, 2 outputs\n",
    "fs = 48000\n",
    "duration = 0.5\n",
    "n_samples = int(fs * duration)\n",
    "\n",
    "# Generate 2 input signals (bandlimited noise in different bands)\n",
    "x1_white = np.random.randn(n_samples)\n",
    "x2_white = np.random.randn(n_samples)\n",
    "\n",
    "# Input 1: 100-2000 Hz\n",
    "sos1 = signal.butter(6, [100, 2000], btype='bandpass', fs=fs, output='sos')\n",
    "x1 = signal.sosfilt(sos1, x1_white)\n",
    "x1 = x1 / np.std(x1) * 0.25\n",
    "\n",
    "# Input 2: 1000-4000 Hz\n",
    "sos2 = signal.butter(6, [1000, 4000], btype='bandpass', fs=fs, output='sos')\n",
    "x2 = signal.sosfilt(sos2, x2_white)\n",
    "x2 = x2 / np.std(x2) * 0.25\n",
    "\n",
    "# Combine into MIMO input: shape (n_samples, I=2)\n",
    "x = np.column_stack([x1, x2])\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Input 1 RMS: {np.sqrt(np.mean(x1**2)):.4f}\")\n",
    "print(f\"Input 2 RMS: {np.sqrt(np.mean(x2**2)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MIMO nonlinear system\n",
    "def mimo_system(x):\n",
    "    \"\"\"\n",
    "    2-input, 2-output nonlinear system.\n",
    "    \n",
    "    Output 1: Primarily driven by input 1, with weak coupling from input 2\n",
    "    Output 2: Primarily driven by input 2, with weak coupling from input 1\n",
    "    \"\"\"\n",
    "    x1, x2 = x[:, 0], x[:, 1]\n",
    "    \n",
    "    # Output 1: linear + quadratic + cubic, with crosstalk\n",
    "    y1_nl = (\n",
    "        0.7 * x1 +                 # Linear (main input)\n",
    "        0.2 * x2 +                 # Linear crosstalk\n",
    "        0.1 * x1**2 +              # Quadratic\n",
    "        0.05 * x1**3 +             # Cubic\n",
    "        0.03 * x1 * x2             # Cross-input interaction\n",
    "    )\n",
    "    \n",
    "    # Output 2: different coefficients, reversed crosstalk\n",
    "    y2_nl = (\n",
    "        0.6 * x2 +                 # Linear (main input)\n",
    "        0.25 * x1 +                # Linear crosstalk\n",
    "        0.12 * x2**2 +             # Quadratic\n",
    "        0.04 * x2**3 +             # Cubic\n",
    "        0.02 * x1 * x2             # Cross-input interaction\n",
    "    )\n",
    "    \n",
    "    # Apply memory (different IIR filters for each output)\n",
    "    b1, a1 = [0.2, -0.38, 0.18], [1.0, -1.9, 0.94]\n",
    "    b2, a2 = [0.18, -0.35, 0.17], [1.0, -1.85, 0.92]\n",
    "    \n",
    "    y1 = signal.lfilter(b1, a1, y1_nl)\n",
    "    y2 = signal.lfilter(b2, a2, y2_nl)\n",
    "    \n",
    "    return np.column_stack([y1, y2])\n",
    "\n",
    "# Generate outputs\n",
    "y_clean = mimo_system(x)\n",
    "\n",
    "# Add noise\n",
    "noise = np.random.randn(n_samples, O) * 0.01\n",
    "y = y_clean + noise\n",
    "\n",
    "print(f\"\\nOutput shape: {y.shape}\")\n",
    "print(f\"Output 1 RMS: {np.sqrt(np.mean(y[:, 0]**2)):.4f}\")\n",
    "print(f\"Output 2 RMS: {np.sqrt(np.mean(y[:, 1]**2)):.4f}\")\n",
    "print(f\"SNR (output 1): {10 * np.log10(np.mean(y_clean[:, 0]**2) / np.mean(noise[:, 0]**2)):.1f} dB\")\n",
    "print(f\"SNR (output 2): {10 * np.log10(np.mean(y_clean[:, 1]**2) / np.mean(noise[:, 1]**2)):.1f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MIMO signals\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 8))\n",
    "\n",
    "n_plot = 2000\n",
    "t_ms = np.arange(n_plot) / fs * 1000\n",
    "\n",
    "# Inputs\n",
    "axes[0, 0].plot(t_ms, x[:n_plot, 0], label='Input 1', alpha=0.7)\n",
    "axes[0, 0].plot(t_ms, x[:n_plot, 1], label='Input 2', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Time (ms)')\n",
    "axes[0, 0].set_ylabel('Amplitude')\n",
    "axes[0, 0].set_title('Input Signals (2 channels)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Outputs\n",
    "axes[0, 1].plot(t_ms, y[:n_plot, 0], label='Output 1', alpha=0.7)\n",
    "axes[0, 1].plot(t_ms, y[:n_plot, 1], label='Output 2', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Time (ms)')\n",
    "axes[0, 1].set_ylabel('Amplitude')\n",
    "axes[0, 1].set_title('Output Signals (2 channels)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Spectra: Input 1\n",
    "f, Pxx1 = signal.welch(x[:, 0], fs=fs, nperseg=2048)\n",
    "f, Pxx2 = signal.welch(x[:, 1], fs=fs, nperseg=2048)\n",
    "axes[1, 0].semilogy(f / 1000, Pxx1, label='Input 1', alpha=0.7)\n",
    "axes[1, 0].semilogy(f / 1000, Pxx2, label='Input 2', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Frequency (kHz)')\n",
    "axes[1, 0].set_ylabel('PSD (V²/Hz)')\n",
    "axes[1, 0].set_title('Input Spectra')\n",
    "axes[1, 0].set_xlim([0, 6])\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Spectra: Outputs\n",
    "f, Pyy1 = signal.welch(y[:, 0], fs=fs, nperseg=2048)\n",
    "f, Pyy2 = signal.welch(y[:, 1], fs=fs, nperseg=2048)\n",
    "axes[1, 1].semilogy(f / 1000, Pyy1, label='Output 1', alpha=0.7)\n",
    "axes[1, 1].semilogy(f / 1000, Pyy2, label='Output 2', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Frequency (kHz)')\n",
    "axes[1, 1].set_ylabel('PSD (V²/Hz)')\n",
    "axes[1, 1].set_title('Output Spectra (with harmonics)')\n",
    "axes[1, 1].set_xlim([0, 6])\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Fit Tensor-Train Volterra Model\n",
    "\n",
    "We'll use `TTVolterraMIMO` with automatic rank selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "n_train = int(0.7 * n_samples)\n",
    "x_train, x_test = x[:n_train], x[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "print(f\"Training samples: {n_train}\")\n",
    "print(f\"Testing samples: {len(x_test)}\")\n",
    "print(f\"Training data shapes: x={x_train.shape}, y={y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TT-Volterra model\n",
    "tt_model = TTVolterraMIMO(\n",
    "    memory_length=8,\n",
    "    order=3,\n",
    "    ranks=[1, 3, 3, 1],  # TT ranks (length = order + 1)\n",
    "    max_iter=30,\n",
    "    lambda_reg=1e-5\n",
    ")\n",
    "\n",
    "print(\"TT-Volterra Model Configuration:\")\n",
    "print(f\"  Memory length: {tt_model.memory_length}\")\n",
    "print(f\"  Nonlinearity order: {tt_model.order}\")\n",
    "print(f\"  TT ranks: {tt_model.ranks}\")\n",
    "print(f\"  Max iterations: {tt_model.max_iter}\")\n",
    "print(f\"  Regularization: {tt_model.lambda_reg}\")\n",
    "\n",
    "# Estimate number of parameters\n",
    "M, N, I_in = tt_model.memory_length, tt_model.order, x_train.shape[1]\n",
    "r = tt_model.ranks[1]  # Assume uniform rank\n",
    "n_params_tt = N * M * I_in * r**2\n",
    "n_params_full = I_in**N * M**N\n",
    "\n",
    "print(f\"\\nParameter comparison:\")\n",
    "print(f\"  TT-Volterra: ~{n_params_tt} parameters\")\n",
    "print(f\"  Full Volterra: {n_params_full} parameters\")\n",
    "print(f\"  Compression ratio: {n_params_full / n_params_tt:.1f}×\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "import time\n",
    "\n",
    "print(\"Fitting TT-Volterra model...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "tt_model.fit(x_train, y_train)\n",
    "\n",
    "fit_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nModel fitted in {fit_time:.2f} seconds\")\n",
    "print(f\"Total parameters (per output): {tt_model.total_parameters()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Evaluate Model Performance\n",
    "\n",
    "Let's evaluate each output separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_test_pred = tt_model.predict(x_test)\n",
    "\n",
    "# Trim ground truth to match prediction length\n",
    "M = tt_model.memory_length\n",
    "y_test_trimmed = y_test[M - 1:]\n",
    "\n",
    "print(f\"Prediction shape: {y_test_pred.shape}\")\n",
    "print(f\"Ground truth (trimmed) shape: {y_test_trimmed.shape}\")\n",
    "\n",
    "# Compute NMSE for each output\n",
    "def compute_nmse(y_true, y_pred):\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    signal_power = np.mean(y_true ** 2)\n",
    "    nmse_db = 10 * np.log10(mse / signal_power)\n",
    "    return nmse_db\n",
    "\n",
    "print(\"\\nTest NMSE (per output):\")\n",
    "for o in range(O):\n",
    "    nmse = compute_nmse(y_test_trimmed[:, o], y_test_pred[:, o])\n",
    "    print(f\"  Output {o + 1}: {nmse:.2f} dB\")\n",
    "\n",
    "# Overall NMSE\n",
    "nmse_overall = compute_nmse(y_test_trimmed.ravel(), y_test_pred.ravel())\n",
    "print(f\"\\nOverall NMSE: {nmse_overall:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions for both outputs\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "n_plot = 1500\n",
    "t_ms = np.arange(n_plot) / fs * 1000\n",
    "\n",
    "for o in range(O):\n",
    "    # Time domain comparison\n",
    "    axes[o, 0].plot(t_ms, y_test_trimmed[:n_plot, o], label='True', alpha=0.7, linewidth=1.5)\n",
    "    axes[o, 0].plot(t_ms, y_test_pred[:n_plot, o], label='TT predicted', alpha=0.7, linewidth=1.5, linestyle='--')\n",
    "    axes[o, 0].set_xlabel('Time (ms)')\n",
    "    axes[o, 0].set_ylabel('Amplitude')\n",
    "    nmse = compute_nmse(y_test_trimmed[:, o], y_test_pred[:, o])\n",
    "    axes[o, 0].set_title(f'Output {o + 1} Prediction (NMSE: {nmse:.2f} dB)')\n",
    "    axes[o, 0].legend()\n",
    "    axes[o, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Prediction error\n",
    "    error = y_test_trimmed[:n_plot, o] - y_test_pred[:n_plot, o]\n",
    "    axes[o, 1].plot(t_ms, error, alpha=0.7, color='red')\n",
    "    axes[o, 1].axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "    axes[o, 1].set_xlabel('Time (ms)')\n",
    "    axes[o, 1].set_ylabel('Error')\n",
    "    axes[o, 1].set_title(f'Output {o + 1} Error (RMS: {np.sqrt(np.mean(error**2)):.4f})')\n",
    "    axes[o, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Scatter: predicted vs. true\n",
    "    axes[o, 2].scatter(y_test_trimmed[::10, o], y_test_pred[::10, o], alpha=0.3, s=2)\n",
    "    y_range = [y_test_trimmed[:, o].min(), y_test_trimmed[:, o].max()]\n",
    "    axes[o, 2].plot(y_range, y_range, 'r--', linewidth=2, label='Perfect')\n",
    "    axes[o, 2].set_xlabel('True output')\n",
    "    axes[o, 2].set_ylabel('Predicted output')\n",
    "    axes[o, 2].set_title(f'Output {o + 1}: Predicted vs. True')\n",
    "    axes[o, 2].legend()\n",
    "    axes[o, 2].grid(True, alpha=0.3)\n",
    "    axes[o, 2].axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Analyze TT Cores and Model Structure\n",
    "\n",
    "Let's examine the learned TT cores to understand the model's internal structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access learned TT cores for first output\n",
    "cores_output_0 = tt_model.get_cores(output_idx=0)\n",
    "\n",
    "print(f\"Number of TT cores (output 0): {len(cores_output_0)}\")\n",
    "print(f\"TT core shapes (order × cores):\")\n",
    "for k, core in enumerate(cores_output_0):\n",
    "    print(f\"  Core {k + 1}: {core.shape}\")\n",
    "\n",
    "# Count total parameters\n",
    "total_params = sum(core.size for core in cores_output_0)\n",
    "print(f\"\\nTotal parameters (output 0): {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize TT core magnitudes\n",
    "fig, axes = plt.subplots(1, len(cores_output_0), figsize=(15, 4))\n",
    "\n",
    "for k, core in enumerate(cores_output_0):\n",
    "    # Reshape core for visualization: (r_{k-1}, memory × inputs, r_k)\n",
    "    # For simplicity, show Frobenius norm per lag\n",
    "    core_norms = np.linalg.norm(core.reshape(core.shape[0], -1, core.shape[-1]), axis=(0, 2))\n",
    "    \n",
    "    axes[k].bar(range(len(core_norms)), core_norms, alpha=0.7, edgecolor='black')\n",
    "    axes[k].set_xlabel('Memory index')\n",
    "    axes[k].set_ylabel('Frobenius norm')\n",
    "    axes[k].set_title(f'Core {k + 1} (Order {k + 1})')\n",
    "    axes[k].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('TT Core Magnitudes (Output 0)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Taller bars indicate more important memory lags for that nonlinearity order\")\n",
    "print(\"  - Core 1 (linear): typically dominates for weakly nonlinear systems\")\n",
    "print(\"  - Cores 2-3 (quadratic/cubic): capture higher-order interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Rank Selection: Impact on Performance\n",
    "\n",
    "How do TT ranks affect model performance? Let's compare different rank configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different TT ranks\n",
    "rank_configs = [\n",
    "    [1, 1, 1, 1],  # Diagonal (rank-1, equivalent to MP)\n",
    "    [1, 2, 2, 1],  # Rank-2\n",
    "    [1, 3, 3, 1],  # Rank-3\n",
    "    [1, 4, 4, 1],  # Rank-4\n",
    "    [1, 5, 5, 1],  # Rank-5\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Testing different TT ranks...\\n\")\n",
    "\n",
    "for ranks in rank_configs:\n",
    "    model = TTVolterraMIMO(\n",
    "        memory_length=8,\n",
    "        order=3,\n",
    "        ranks=ranks,\n",
    "        max_iter=20,\n",
    "        lambda_reg=1e-5\n",
    "    )\n",
    "    \n",
    "    # Fit and predict\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    fit_time = time.time() - start\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    nmse = compute_nmse(y_test_trimmed.ravel(), y_pred.ravel())\n",
    "    n_params = model.total_parameters()\n",
    "    \n",
    "    results.append({\n",
    "        'ranks': ranks,\n",
    "        'max_rank': max(ranks),\n",
    "        'n_params': n_params,\n",
    "        'nmse_db': nmse,\n",
    "        'fit_time': fit_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Ranks {ranks}: {n_params:4d} params, NMSE = {nmse:6.2f} dB, time = {fit_time:.2f}s\")\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "max_ranks = [r['max_rank'] for r in results]\n",
    "n_params = [r['n_params'] for r in results]\n",
    "nmses = [r['nmse_db'] for r in results]\n",
    "fit_times = [r['fit_time'] for r in results]\n",
    "\n",
    "# NMSE vs. parameters\n",
    "axes[0].plot(n_params, nmses, 'o-', markersize=10, linewidth=2)\n",
    "for i, r in enumerate(results):\n",
    "    axes[0].text(n_params[i], nmses[i] + 0.5, f\"r={r['max_rank']}\", \n",
    "                ha='center', fontsize=10, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Parameters')\n",
    "axes[0].set_ylabel('Test NMSE (dB)')\n",
    "axes[0].set_title('Rank vs. Performance Trade-off')\n",
    "axes[0].axhline(-20, color='green', linestyle='--', linewidth=1.5, alpha=0.5, label='Excellent')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Fit time vs. rank\n",
    "axes[1].bar(range(len(max_ranks)), fit_times, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xticks(range(len(max_ranks)))\n",
    "axes[1].set_xticklabels([f\"r={r}\" for r in max_ranks])\n",
    "axes[1].set_xlabel('Max TT Rank')\n",
    "axes[1].set_ylabel('Fit Time (seconds)')\n",
    "axes[1].set_title('Computational Cost vs. Rank')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey observations:\")\n",
    "print(\"  - Rank 1 = diagonal (MP-equivalent): fast but may underfit\")\n",
    "print(\"  - Higher ranks capture more complex interactions\")\n",
    "print(\"  - Diminishing returns: rank 3-4 often sufficient for many systems\")\n",
    "print(\"  - Fit time increases ~quadratically with rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Generated MIMO nonlinear system data** (2 inputs, 2 outputs)\n",
    "2. **Fitted Tensor-Train Volterra model** with automatic rank selection\n",
    "3. **Evaluated performance** for each output channel\n",
    "4. **Analyzed TT core structure** to understand learned representations\n",
    "5. **Compared different TT ranks** to guide hyperparameter selection\n",
    "\n",
    "### When to use TT-Volterra:\n",
    "- ✅ **High-dimensional MIMO** (many inputs/outputs)\n",
    "- ✅ **High order or long memory** (N > 3 or M > 10)\n",
    "- ✅ **Parameter efficiency critical** (embedded systems, real-time)\n",
    "- ✅ **Full cross-input interactions** needed (not just diagonal)\n",
    "- ❌ **Low-dimensional SISO** → use MP or GMP (simpler, faster)\n",
    "- ❌ **Very large datasets** → TT-ALS can be slow (use stochastic methods)\n",
    "\n",
    "### Practical recommendations:\n",
    "1. **Start with rank 2-3** for most applications\n",
    "2. **Increase rank if underfitting** (poor NMSE)\n",
    "3. **Use regularization** (`lambda_reg > 0`) to prevent overfitting\n",
    "4. **Monitor convergence** via `fit_info_` diagnostics\n",
    "5. **Consider rank adaptation** (TT-MALS) for automatic rank selection\n",
    "\n",
    "### Computational complexity:\n",
    "- **TT-Volterra**: $O(N \\cdot M \\cdot I \\cdot r^2 \\cdot T)$ per iteration\n",
    "- **Full Volterra**: $O(I^N \\cdot M^N \\cdot T)$ — intractable for N > 3!\n",
    "- **Memory Polynomial**: $O(M \\cdot N \\cdot T)$ — fastest, but limited expressiveness\n",
    "\n",
    "### Next steps:\n",
    "- **Notebook 03**: Automatic model selection (MP vs GMP vs TT-Full)\n",
    "- **Notebook 04**: Real-world application (instrument + room pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
